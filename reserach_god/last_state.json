{
  "code_tracker.py": "from pathlib import Path\nimport difflib\nfrom datetime import datetime\nfrom openai import OpenAI\nimport os\nfrom dotenv import load_dotenv\nimport json\n\n# Load environment variables for OpenAI\nload_dotenv()\n\nclass CodeChangeTracker:\n    def __init__(self):\n        self.client = OpenAI()\n        self.last_state_file = \"last_state.json\"\n        self.tracked_extensions = ['.py', '.txt', '.md']  # Files to track\n        \n    def get_file_contents(self):\n        \"\"\"Get current content of all tracked files\"\"\"\n        current_state = {}\n        for ext in self.tracked_extensions:\n            for file in Path('.').glob(f'*{ext}'):\n                # Skip certain files\n                if any(skip in str(file) for skip in ['__pycache__', '.git', 'last_state.json']):\n                    continue\n                    \n                try:\n                    with open(file, 'r', encoding='utf-8') as f:\n                        current_state[str(file)] = f.read()\n                except UnicodeDecodeError:\n                    print(f\"Skipping binary file: {file}\")\n                except Exception as e:\n                    print(f\"Error reading {file}: {str(e)}\")\n        \n        return current_state\n\n    def analyze_changes(self):\n        \"\"\"Compare current files with last saved state\"\"\"\n        current_state = self.get_file_contents()\n        \n        # Load previous state if exists\n        try:\n            if os.path.exists(self.last_state_file):\n                with open(self.last_state_file, 'r', encoding='utf-8') as f:\n                    previous_state = json.load(f)\n            else:\n                previous_state = {}\n        except Exception:\n            previous_state = {}\n\n        # Save current state for next comparison\n        with open(self.last_state_file, 'w', encoding='utf-8') as f:\n            json.dump(current_state, f, indent=2)\n\n        if not previous_state:\n            return \"Initial state saved\"\n\n        # Compare states and collect changes\n        changes = []\n        for file in set(current_state.keys()) | set(previous_state.keys()):\n            if file not in previous_state:\n                changes.append(f\"New file created: {file}\")\n            elif file not in current_state:\n                changes.append(f\"File deleted: {file}\")\n            elif current_state[file] != previous_state[file]:\n                diff = list(difflib.unified_diff(\n                    previous_state[file].splitlines(),\n                    current_state[file].splitlines(),\n                    fromfile=f'previous/{Path(file).name}',\n                    tofile=f'current/{Path(file).name}',\n                    lineterm=''\n                ))\n                if diff:\n                    changes.append(f\"\\nChanges in {file}:\\n\" + '\\n'.join(diff))\n\n        if not changes:\n            return \"No changes detected\"\n\n        # Use GPT to analyze the changes\n        prompt = f\"\"\"\n        Analyze these code and file changes and provide a clear, organized summary:\n\n        {changes}\n\n        Please provide:\n        1. A concise bullet-point list of significant changes\n        2. Focus on functional changes (ignore formatting changes)\n        3. Group related changes together\n        4. Highlight any new features or important modifications\n        5. Mention any new files or major file changes\n\n        Format the response as markdown-compatible text.\n        \"\"\"\n\n        try:\n            response = self.client.chat.completions.create(\n                model=\"gpt-4-turbo-preview\",\n                messages=[{\"role\": \"user\", \"content\": prompt}]\n            )\n            return response.choices[0].message.content\n        except Exception as e:\n            return f\"Error analyzing changes with GPT: {str(e)}\\n\\nRaw changes:\\n\" + \"\\n\".join(changes)\n\ndef update_progress_file(changes: str):\n    \"\"\"Update PROGRESS.md with latest changes\"\"\"\n    if changes in [\"No changes detected\", \"Initial state saved\"]:\n        return\n        \n    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n    \n    new_entry = f\"\"\"\n## Update {timestamp}\n\n{changes}\n\n---\n\"\"\"\n    \n    progress_file = Path(\"PROGRESS.md\")\n    if not progress_file.exists():\n        content = \"# Development Progress\\n\\nTrack of changes made to the research script.\\n\\n\"\n    else:\n        content = progress_file.read_text(encoding='utf-8')\n    \n    with open(progress_file, \"w\", encoding='utf-8') as f:\n        f.write(content + new_entry) ",
  "main.py": "from openai import OpenAI\nfrom dotenv import load_dotenv\nimport os\nimport json\nfrom typing import List, Dict\nimport datetime\nimport asyncio\nimport aiohttp\nfrom code_tracker import CodeChangeTracker, update_progress_file\n\n# Load environment variables\nload_dotenv()\nprint(\"Environment variables loaded...\")\n\n# Initialize clients\nopenai_client = OpenAI()\nperplexity_client = OpenAI(\n    api_key=os.getenv(\"PERPLEXITY_API_KEY\"),\n    base_url=\"https://api.perplexity.ai\"\n)\nprint(\"API clients initialized...\")\n\ndef choose_mode() -> str:\n    \"\"\"Choose between fast mode (smaller model) or quality mode (larger model)\"\"\"\n    print(\"\\nAvailable modes:\")\n    print(\"1. Quality mode (default) - Uses more powerful model for better results\")\n    print(\"2. Fast mode - Uses lighter model for quicker results\")\n    \n    choice = input(\"\\nDo you want to run in fast mode? (y/n): \").lower()\n    \n    if choice == 'y':\n        print(\"\u2713 Fast mode selected - Using llama-3.1-sonar-small-128k-online\")\n        return \"llama-3.1-sonar-small-128k-online\"\n    else:\n        print(\"\u2713 Quality mode selected - Using llama-3.1-sonar-large-128k-online\")\n        return \"llama-3.1-sonar-large-128k-online\"\n\ndef generate_research_queries(user_input: str) -> Dict:\n    \"\"\"First agent: Generates research queries based on user input\"\"\"\n    print(f\"\\n1. Generating research queries for: '{user_input}'\")\n    \n    prompt = f\"\"\"\n    You are a research query generator. Your task is to deeply analyze the user's query to understand their core research needs and generate targeted search queries.\n    If it makes sense, use your own knowledge to improve prompts - if you know it's smart to research something more than the user asked, do it.\n\n    1. First, identify the main topics, subtopics, and any specific aspects mentioned in the query\n    2. Consider different angles, perspectives, and related areas that would provide comprehensive research coverage\n    3. Generate search queries that:\n        - Must be highly specific and distinct from each other\n        - Approach the topic from radically different angles and perspectives\n        - Use precise technical terminology and domain-specific language\n        - Target niche subtopics and specialized aspects\n        - Include contrasting viewpoints and alternative interpretations\n        - Focus on unique case studies and specific examples\n        - Examine interconnections with other fields/domains\n        - Look for cutting-edge research and emerging trends\n        - Seek expert analysis and authoritative sources\n        - Consider historical context and future implications\n\n    Return a JSON object with this structure:\n    {{\n        \"user_prompt\": \"Original user query\",\n        \"topic_analysis\": \"Your detailed analysis of main topics and diverse research angles\",\n        \"search_queries\": [\n            \"Array of 10 highly distinct and specific search queries, each exploring a unique aspect or perspective of the topic\"\n        ]\n    }}\n    \n    User Query: {user_input}\n    \"\"\"\n    \n    response = openai_client.chat.completions.create(\n        model=\"gpt-4-turbo-preview\",\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n        response_format={ \"type\": \"json_object\" }\n    )\n    \n    result = json.loads(response.choices[0].message.content)\n    \n    # Print the reasoning/analysis first\n    print(\"\\n\u2713 Topic Analysis:\")\n    print(f\"{result['topic_analysis']}\")\n    \n    # Then print the queries\n    print(\"\\n\u2713 Generated research queries:\")\n    for i, query in enumerate(result['search_queries'], 1):\n        print(f\"   {i}. {query}\")\n    \n    return result\n\nasync def perform_single_search(session, query: str, i: int, model: str) -> Dict:\n    \"\"\"Perform a single search query\"\"\"\n    try:\n        async with session.post(\n            \"https://api.perplexity.ai/chat/completions\",\n            headers={\n                \"Authorization\": f\"Bearer {os.getenv('PERPLEXITY_API_KEY')}\",\n                \"Content-Type\": \"application/json\"\n            },\n            json={\n                \"model\": model,\n                \"messages\": [\n                    {\n                        \"role\": \"system\",\n                        \"content\": (\n                            \"You are a highly analytical research assistant focused on evidence-based findings. \"\n                            \"Your task is to:\\n\"\n                            \"1. Deeply analyze the query to understand the core research needs\\n\"\n                            \"2. Provide strictly factual information supported by reliable sources\\n\"\n                            \"3. Focus on recent, peer-reviewed research and authoritative sources\\n\"\n                            \"4. Draw precise conclusions that directly address the query context\\n\"\n                            \"5. Prioritize accuracy and relevance over breadth\\n\"\n                            \"6. Cite specific studies, papers, or expert sources where possible\\n\"\n                            \"7. Highlight any important caveats or limitations in the findings\\n\\n\"\n                            \"Ensure your response is concise, well-structured, and directly addresses \"\n                            \"the key aspects of the query while maintaining strict factual accuracy.\"\n                        ),\n                    },\n                    {\n                        \"role\": \"user\",\n                        \"content\": query,\n                    },\n                ]\n            }\n        ) as response:\n            result = await response.json()\n            return {\n                \"query\": query,\n                \"response\": result['choices'][0]['message']['content']\n            }\n    except Exception as e:\n        print(f\"\\n   \u2717 Error in search {i}: {str(e)}\")\n        return {\n            \"query\": query,\n            \"response\": f\"Error: {str(e)}\"\n        }\n\nasync def perform_web_searches_async(queries: List[str], model: str) -> List[Dict]:\n    \"\"\"Performs web searches using Perplexity API concurrently\"\"\"\n    print(\"\\n2. Performing web searches concurrently...\")\n    total_queries = len(queries)\n    completed_queries = 0\n    \n    async def search_with_progress(session, query: str, i: int) -> Dict:\n        nonlocal completed_queries\n        print(f\"\\r   Progress: {completed_queries}/{total_queries} queries completed ({(completed_queries/total_queries)*100:.1f}%)\", end=\"\")\n        \n        result = await perform_single_search(session, query, i, model)\n        \n        completed_queries += 1\n        print(f\"\\r   Progress: {completed_queries}/{total_queries} queries completed ({(completed_queries/total_queries)*100:.1f}%)\", end=\"\")\n        return result\n    \n    async with aiohttp.ClientSession() as session:\n        tasks = [\n            search_with_progress(session, query, i+1) \n            for i, query in enumerate(queries)\n        ]\n        results = await asyncio.gather(*tasks)\n    \n    print(\"\\n   \u2713 All searches completed\")\n    return results\n\ndef perform_web_searches(queries: List[str], model: str) -> List[Dict]:\n    \"\"\"Wrapper function to run async searches\"\"\"\n    return asyncio.run(perform_web_searches_async(queries, model))\n\ndef synthesize_research(original_prompt: str, search_results: List[Dict]) -> str:\n    \"\"\"Second agent: Synthesizes all research into a final answer\"\"\"\n    print(\"\\n3. Synthesizing research findings...\")\n    \n    synthesis_prompt = f\"\"\"\n    Original user query: {original_prompt}\n    \n    Research findings:\n    {json.dumps(search_results, indent=2)}\n    \n    Please analyze these findings deeply and synthesize them into a clear, engaging answer that directly addresses the user's needs:\n\n    1. Focus only on information that is most relevant to the user's original query\n    2. Present complex concepts in simple, easy-to-understand language\n    3. Structure the response in a captivating way that maintains reader interest\n    4. Highlight key insights and practical takeaways\n    5. Omit any information that doesn't directly help answer the user's question\n    6. Use clear examples and analogies where helpful\n    7. Write in an engaging, conversational tone while maintaining accuracy\n\n    In addition to synthesizing the research findings, please provide:\n    - A brief summary of the main points and key takeaways\n    - Simple, actionable advice on what the user should do next with this information\n    - Bullet points or lists where appropriate to improve readability\n\n    Your response should be captivating yet concise - make complex ideas crystal clear while keeping readers hooked from start to finish. Write like you're telling a fascinating story, not delivering a dry lecture. Make the output more concrete with detailed action steps when it makes sense.\n\n    \"\"\"\n    \n    response = openai_client.chat.completions.create(\n        model=\"gpt-4-turbo-preview\",\n        messages=[{\"role\": \"user\", \"content\": synthesis_prompt}]\n    )\n    \n    print(\"\u2713 Research synthesis completed\")\n    return response.choices[0].message.content\n\ndef get_next_file_number():\n    \"\"\"Get the next available file number by checking existing files\"\"\"\n    os.makedirs(\"research_results\", exist_ok=True)\n    existing_files = os.listdir(\"research_results\")\n    numbers = [int(f.split('_')[1].split('.')[0]) for f in existing_files \n              if f.startswith('research_') and f.endswith('.md')]\n    return max(numbers, default=0) + 1\n\ndef save_to_markdown(user_input: str, result: str, research_plan: Dict, execution_time: float):\n    \"\"\"Save research results to a markdown file with sequential numbering\"\"\"\n    # Get next available number\n    file_number = get_next_file_number()\n    \n    # Create filename with just the number\n    filename = f\"research_{file_number:04d}.md\"\n    filepath = os.path.join(\"research_results\", filename)\n    \n    # Get simplified prompt from research plan\n    simplified_prompt = research_plan.get('topic_analysis', 'Topic analysis not available')\n    \n    # Format the markdown content\n    content = f\"\"\"# Research #{file_number}\n\n## Timestamp\n{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n\n## Execution Time\n{execution_time:.2f} seconds\n\n## Original Query\n{user_input}\n\n## Topic Analysis\n{simplified_prompt}\n\n## Findings\n{result}\n\"\"\"\n    \n    # Save the file\n    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n        f.write(content)\n    \n    print(f\"\\n\u2713 Results saved to {filepath}\")\n\ndef research(user_input: str) -> tuple[str, Dict, float]:\n    \"\"\"Main research pipeline\"\"\"\n    start_time = datetime.datetime.now()\n    print(\"\\n=== Starting Research Process ===\")\n    \n    # Choose mode at the start\n    model = choose_mode()\n    \n    # Step 1: Generate queries\n    research_plan = generate_research_queries(user_input)\n    print(\"Research queries generated...\")\n    \n    # Step 2: Perform web searches with selected model\n    search_results = perform_web_searches(research_plan['search_queries'], model)\n    print(\"Web searches completed...\")\n    \n    # Step 3: Synthesize final answer\n    final_answer = synthesize_research(user_input, search_results)\n    print(\"Research synthesis completed...\")\n    \n    # Calculate execution time\n    execution_time = (datetime.datetime.now() - start_time).total_seconds()\n    \n    print(\"\\n=== Research Process Completed ===\")\n    print(f\"Total execution time: {execution_time:.2f} seconds\")\n    \n    return final_answer, research_plan, execution_time\n\nif __name__ == \"__main__\":\n    # Track code changes\n    tracker = CodeChangeTracker()\n    \n    # Analyze changes (no need to save version separately anymore)\n    changes = tracker.analyze_changes()\n    \n    # Update progress file if there are changes\n    if changes and changes not in [\"No changes detected\", \"Initial state saved\"]:\n        update_progress_file(changes)\n    \n    # Rest of your main code...\n    user_input = input(\"\\nEnter your research question: \")\n    print(\"\\nFinal Result:\")\n    print(\"-\" * 50)\n    result, research_plan, execution_time = research(user_input)\n    print(result)\n    \n    # Save to markdown file\n    save_to_markdown(user_input, result, research_plan, execution_time)\n",
  "improvements.txt": "how to use 2024 data - add browse the web prompt\n\nhow to use improvements.txt and prompts.txt\n\n\n\n",
  "prompts.txt": "Economic Collapse and the Great Depression: How global economic instability in the 1930s created fertile ground for extremist ideologies and militaristic governments.\n\nInvasion of Poland: What made the invasion of Poland a pivotal event in starting WWII, and could diplomacy have stopped the conflict after Germany\u2019s initial invasion?\n\nBattle of Britain and Air Warfare: How did the Battle of Britain change perceptions of air warfare in WWII, and what role did air power play in both Allied and Axis strategies?\n\nD-Day and the Liberation of Europe: How did D-Day mark a turning point for the Allies, and what were the strategic challenges involved in planning and executing the \ninvasion?\n\nThe Pacific Theater and Pearl Harbor: How did the attack on Pearl Harbor reshape American involvement in WWII, and what unique challenges defined the Pacific Theater compared to the European front?",
  "PROGRESS.md": "\n## Update 2024-11-05 08:19:54\n\nBased on the information provided:\n\n- **New file added**:\n  - `requirements.txt` has been created. \n\nSince there are no specific changes within files detailed beyond the creation of a `requirements.txt`, the summary is focused solely on this addition. Further details on the contents of `requirements.txt` or implications on the project functionality cannot be provided without additional context.\n\n---\n\n## Update 2024-11-05 08:28:34\n\nBased on the provided code and file changes, here's a structured summary of significant modifications, focusing on functional alterations:\n\n### **main.py Changes**\n\n- **Simplification and Redundancy Removal:**\n  - The `print` statement and the definition of the `messages` variable within the `perform_single_search` function have been removed, with the `messages` variable being reintegrated directly within the API call in a simplified format. This adjustment makes the code more concise and eliminates unnecessary redundancy.\n\n- **Error Handling Enhancement:**\n  - The error message printed upon an exception during search has been altered to include a line break (`\\n`) at the beginning, aiming to improve readability in the console output.\n\n- **Progress Tracking Feature:**\n  - A new feature has been added to track the progress of queries processed in the `perform_web_searches_async` function. The following sub-points detail this enhancement:\n    - Introduction of `total_queries` and `completed_queries` variables to keep track of the overall progress.\n    - A new nested function `search_with_progress` wraps around the `perform_single_search` call to update and print the progress after each query is completed.\n    - Modification in the handling of tasks to utilize `search_with_progress` instead of directly calling `perform_single_search`, enabling real-time progress feedback in the console.\n\n- **Completion Notification:**\n  - A print statement has been added to signal the completion of all searches, enhancing user feedback by explicitly indicating when all tasks are done.\n\n### **PROGRESS.md Changes**\n\n- **Documentation Enhancement:**\n  - A minor adjustment has been made to the documentation in `PROGRESS.md`, marking an update without specific content changes detailed in the provided snippet. This likely serves as a placeholder or timestamp for tracking progress or modifications in a project timeline.\n\n### **Overall Summary of Modifications:**\n\n- Code cleanup in `main.py` through the removal of redundant code and more seamless integration of variable definitions.\n- Improvement in error handling user feedback with formatting adjustments.\n- Implementation of a new progress tracking feature, enhancing user interaction by providing real-time updates on the processing of queries.\n- Introduction of a user notification indicating the completion of all search queries, aiming to improve the usability and feedback loop of the script.\n- Minor administrative update in `PROGRESS.md`, which seems to serve documentation or progression tracking purposes within the project.\n\n---\n\n## Update 2024-11-05 15:30:22\n\nHere's a structured summary of the significant modifications based on the provided details:\n\n### **main.py Changes**\n\n- **Simplification and Redundancy Removal:**\n  - Removed unnecessary `print` statement and the redundant definition of the `messages` variable in `perform_single_search`. Now, the `messages` variable is directly integrated within the API call, simplifying the code.\n\n- **Error Handling Enhancement:**\n  - Modified error message format to include a line break at the beginning for improved readability in console output.\n\n- **New Progress Tracking Feature:**\n  - Added variables (`total_queries` and `completed_queries`) to track progress of queries processed.\n  - Implemented a nested function `search_with_progress` to wrap the `perform_single_search` call, updating and printing progress after each query completion.\n  - Adjusted task handling to use `search_with_progress` for real-time progress feedback during the execution of queries.\n\n- **Completion Notification:**\n  - A new print statement indicates when all search queries have been processed, improving user feedback.\n\n### **PROGRESS.md Changes**\n\n- **Documentation Enhancement:**\n  - Made a minor update, likely for tracking project progress or modifications.\n\n### **Overall Summary of Modifications:**\n\n- **Code Efficiency:** Streamlined `main.py` by removing redundant code and integrating variables more seamlessly.\n- **User Feedback Enhancement:** Improved error handling feedback and introduced a completion notification for better user interaction.\n- **Progress Tracking:** Implemented a new feature to track and display the progress of query processing in real time.\n- **Documentation Update:** Minor update in `PROGRESS.md` for administrative purposes, possibly related to project progression tracking.\n\n---\n\n## Update 2024-11-05 17:23:40\n\n```markdown\n## Summary of Significant Changes\n\n### **Functional Improvements and Updates**\n\n- #### improvements.txt Modifications\n  - Updated the guidance on \"how to use 2024 data\" by **adding a prompt to browse the web**. This indicates an enhanced user instruction for interacting with 2024 data.\n\n### **main.py Enhancements**\n- **Code Simplification and Redundancy Removal**\n  - Unnecessary `print` statements removed and redundancy of the `messages` variable in `perform_single_search` eliminated. The `messages` variable is now directly utilized within the API call, streamlining the function.\n\n- **Error Handling Improvements**\n  - Modified the format of error messages to improve readability by **adding a line break** at the beginning of the message in console outputs.\n\n- **New Progress Tracking Feature**\n  - Introduced variables (`total_queries` and `completed_queries`) to **track the progress** of queries being processed.\n  - Implemented a new nested function `search_with_progress` to wrap around `perform_single_search` calls. This function updates and prints the completion progress after each query, enhancing real-time feedback to the user.\n  - Modified task handling to employ `search_with_progress`, providing a real-time progress indicator during query execution.\n\n- **Completion Notification**\n  - Added a **new print statement** to signal when all search queries have been processed, aimed at improving user interaction and feedback.\n\n### **PROGRESS.md Documentation Update**\n\n- **Minor Update for Progress Tracking**\n  - A minor but possibly significant administrative update was made, likely for the purpose of **documenting project progression or changes**.\n\n### **Overall Impact of Modifications**\n\n- **Efficiency and Cleanliness of Code**\n  - The `main.py` file has been streamlined by removing unnecessary elements and integrating variables more effectively, leading to a cleaner and more efficient codebase.\n\n- **Enhanced User Feedback**\n  - The modifications have improved error messaging for better readability and introduced a completion indicator, significantly improving the user's interaction and understanding of the process.\n\n- **Progress Tracking Implementation**\n  - The addition of a new feature for **tracking and displaying query processing progress** in real-time demonstrates an investment in user experience and operational transparency.\n\n- **Documentation Enhancements**\n  - Even a minor update to the `PROGRESS.md` file reflects an ongoing effort to keep project documentation current, which is essential for tracking and understanding project evolution.\n```\n\n\n---\n"
}